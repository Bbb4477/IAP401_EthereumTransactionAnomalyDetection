{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1808584,"sourceType":"datasetVersion","datasetId":1074447},{"sourceId":12872725,"sourceType":"datasetVersion","datasetId":8143074}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# !pip install category_encoders\n\nfrom sklearn.model_selection import train_test_split\nfrom category_encoders import TargetEncoder\nfrom sklearn.ensemble import IsolationForest\nfrom sklearn.manifold import TSNE\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:33:41.633477Z","iopub.execute_input":"2025-08-27T02:33:41.633792Z","iopub.status.idle":"2025-08-27T02:34:11.546612Z","shell.execute_reply.started":"2025-08-27T02:33:41.633770Z","shell.execute_reply":"2025-08-27T02:34:11.545165Z"},"jupyter":{"outputs_hidden":true},"collapsed":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/ethereum-frauddetection-dataset/transaction_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:34:55.856242Z","iopub.execute_input":"2025-08-27T02:34:55.856606Z","iopub.status.idle":"2025-08-27T02:34:55.932414Z","shell.execute_reply.started":"2025-08-27T02:34:55.856584Z","shell.execute_reply":"2025-08-27T02:34:55.931414Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:34:58.463770Z","iopub.execute_input":"2025-08-27T02:34:58.464202Z","iopub.status.idle":"2025-08-27T02:34:58.495331Z","shell.execute_reply.started":"2025-08-27T02:34:58.464165Z","shell.execute_reply":"2025-08-27T02:34:58.493956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:00.737019Z","iopub.execute_input":"2025-08-27T02:35:00.737371Z","iopub.status.idle":"2025-08-27T02:35:00.761176Z","shell.execute_reply.started":"2025-08-27T02:35:00.737348Z","shell.execute_reply":"2025-08-27T02:35:00.760199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:03.781961Z","iopub.execute_input":"2025-08-27T02:35:03.782307Z","iopub.status.idle":"2025-08-27T02:35:03.803156Z","shell.execute_reply.started":"2025-08-27T02:35:03.782283Z","shell.execute_reply":"2025-08-27T02:35:03.801908Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of rows in DataFrame is {df.shape[0]}\")\nprint(f\"Number of columns in DataFrame is {df.shape[1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:08.126186Z","iopub.execute_input":"2025-08-27T02:35:08.126496Z","iopub.status.idle":"2025-08-27T02:35:08.132653Z","shell.execute_reply.started":"2025-08-27T02:35:08.126475Z","shell.execute_reply":"2025-08-27T02:35:08.131517Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:20.997243Z","iopub.execute_input":"2025-08-27T02:35:20.997571Z","iopub.status.idle":"2025-08-27T02:35:21.010886Z","shell.execute_reply.started":"2025-08-27T02:35:20.997549Z","shell.execute_reply":"2025-08-27T02:35:21.010133Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Number of NaN values in each columns:\\n\\n\", df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:25.265482Z","iopub.execute_input":"2025-08-27T02:35:25.265796Z","iopub.status.idle":"2025-08-27T02:35:25.277213Z","shell.execute_reply.started":"2025-08-27T02:35:25.265775Z","shell.execute_reply":"2025-08-27T02:35:25.275870Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Total number of NaN values is {df.isnull().sum().sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:29.527917Z","iopub.execute_input":"2025-08-27T02:35:29.528237Z","iopub.status.idle":"2025-08-27T02:35:29.539379Z","shell.execute_reply.started":"2025-08-27T02:35:29.528215Z","shell.execute_reply":"2025-08-27T02:35:29.538343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of duplicated values in Index columns is {df.duplicated(subset='Index').sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:38.835359Z","iopub.execute_input":"2025-08-27T02:35:38.835709Z","iopub.status.idle":"2025-08-27T02:35:38.841469Z","shell.execute_reply.started":"2025-08-27T02:35:38.835686Z","shell.execute_reply":"2025-08-27T02:35:38.840429Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of duplicated values is {df.duplicated().sum()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:42.241268Z","iopub.execute_input":"2025-08-27T02:35:42.241605Z","iopub.status.idle":"2025-08-27T02:35:42.266721Z","shell.execute_reply.started":"2025-08-27T02:35:42.241584Z","shell.execute_reply":"2025-08-27T02:35:42.265816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Change the name of columns\ndf.columns = df.columns.str.strip().str.replace(r'\\b\\s+\\b', '_', regex=True)\ndf.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:44.442214Z","iopub.execute_input":"2025-08-27T02:35:44.442559Z","iopub.status.idle":"2025-08-27T02:35:44.451624Z","shell.execute_reply.started":"2025-08-27T02:35:44.442537Z","shell.execute_reply":"2025-08-27T02:35:44.450498Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:48.026526Z","iopub.execute_input":"2025-08-27T02:35:48.027279Z","iopub.status.idle":"2025-08-27T02:35:48.139654Z","shell.execute_reply.started":"2025-08-27T02:35:48.027251Z","shell.execute_reply":"2025-08-27T02:35:48.138536Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show number of values in each class in percent\ndf['FLAG'].value_counts(normalize=True) * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:53.091001Z","iopub.execute_input":"2025-08-27T02:35:53.091330Z","iopub.status.idle":"2025-08-27T02:35:53.099561Z","shell.execute_reply.started":"2025-08-27T02:35:53.091310Z","shell.execute_reply":"2025-08-27T02:35:53.098524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[df.duplicated(subset='Index')]['FLAG'].value_counts(normalize=True) * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:56.681340Z","iopub.execute_input":"2025-08-27T02:35:56.682383Z","iopub.status.idle":"2025-08-27T02:35:56.693179Z","shell.execute_reply.started":"2025-08-27T02:35:56.682357Z","shell.execute_reply":"2025-08-27T02:35:56.692313Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.drop(columns=['Unnamed: 0', 'Index', 'Address'], axis=0, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:35:59.057799Z","iopub.execute_input":"2025-08-27T02:35:59.058130Z","iopub.status.idle":"2025-08-27T02:35:59.065602Z","shell.execute_reply.started":"2025-08-27T02:35:59.058108Z","shell.execute_reply":"2025-08-27T02:35:59.063876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:02.084575Z","iopub.execute_input":"2025-08-27T02:36:02.085562Z","iopub.status.idle":"2025-08-27T02:36:02.114002Z","shell.execute_reply.started":"2025-08-27T02:36:02.085530Z","shell.execute_reply":"2025-08-27T02:36:02.112915Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categories = df.select_dtypes(include=['object']).columns\n\nfor i in categories:\n    print(f\"The number of unique values in {i} is {df[i].nunique()} and it has {df[i].isnull().sum()} NaN values\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:06.291656Z","iopub.execute_input":"2025-08-27T02:36:06.291946Z","iopub.status.idle":"2025-08-27T02:36:06.302780Z","shell.execute_reply.started":"2025-08-27T02:36:06.291925Z","shell.execute_reply":"2025-08-27T02:36:06.301716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric = df.select_dtypes(include=['number']).columns\nconstant_var = [i for i in numeric if df[i].var() == 0]\nprint(f\"Number of features that have constant value is {len(constant_var)}\")\nconstant_var","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:09.099389Z","iopub.execute_input":"2025-08-27T02:36:09.099744Z","iopub.status.idle":"2025-08-27T02:36:09.114923Z","shell.execute_reply.started":"2025-08-27T02:36:09.099722Z","shell.execute_reply":"2025-08-27T02:36:09.113820Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop constant variance features\ndf.drop(columns=constant_var, axis=0, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:12.102717Z","iopub.execute_input":"2025-08-27T02:36:12.103031Z","iopub.status.idle":"2025-08-27T02:36:12.110206Z","shell.execute_reply.started":"2025-08-27T02:36:12.103009Z","shell.execute_reply":"2025-08-27T02:36:12.108873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:14.851195Z","iopub.execute_input":"2025-08-27T02:36:14.851569Z","iopub.status.idle":"2025-08-27T02:36:14.889840Z","shell.execute_reply.started":"2025-08-27T02:36:14.851545Z","shell.execute_reply":"2025-08-27T02:36:14.888721Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 7))\nnumeric = df.select_dtypes(include=['number']).columns\ncorr = df[numeric].corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr, mask=mask, annot=False, vmin=-1, vmax=1)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:17.308692Z","iopub.execute_input":"2025-08-27T02:36:17.309020Z","iopub.status.idle":"2025-08-27T02:36:18.245148Z","shell.execute_reply.started":"2025-08-27T02:36:17.308998Z","shell.execute_reply":"2025-08-27T02:36:18.244276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.heatmap(df.isnull(), cmap='coolwarm', cbar=False)\nplt.yticks([])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:22.265012Z","iopub.execute_input":"2025-08-27T02:36:22.265326Z","iopub.status.idle":"2025-08-27T02:36:23.147486Z","shell.execute_reply.started":"2025-08-27T02:36:22.265304Z","shell.execute_reply":"2025-08-27T02:36:23.146729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Number of rows that has at least one missing value: {df.isnull().any(axis=1).sum()}\")\nmissing_mask = df.isnull().any(axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:27.589520Z","iopub.execute_input":"2025-08-27T02:36:27.589813Z","iopub.status.idle":"2025-08-27T02:36:27.602980Z","shell.execute_reply.started":"2025-08-27T02:36:27.589795Z","shell.execute_reply":"2025-08-27T02:36:27.601396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.loc[missing_mask, 'FLAG'].value_counts())\nprint()\nprint(round(df.loc[missing_mask, 'FLAG'].value_counts(normalize=True), 2) * 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:31.058177Z","iopub.execute_input":"2025-08-27T02:36:31.058552Z","iopub.status.idle":"2025-08-27T02:36:31.070092Z","shell.execute_reply.started":"2025-08-27T02:36:31.058527Z","shell.execute_reply":"2025-08-27T02:36:31.068712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df['FLAG'].value_counts())\nprint()\nprint(round(df['FLAG'].value_counts(normalize=True), 2) * 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:33.676145Z","iopub.execute_input":"2025-08-27T02:36:33.676525Z","iopub.status.idle":"2025-08-27T02:36:33.684833Z","shell.execute_reply.started":"2025-08-27T02:36:33.676494Z","shell.execute_reply":"2025-08-27T02:36:33.683888Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df[~missing_mask].shape)\nsub_df = df[~missing_mask]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:36.462521Z","iopub.execute_input":"2025-08-27T02:36:36.462820Z","iopub.status.idle":"2025-08-27T02:36:36.472505Z","shell.execute_reply.started":"2025-08-27T02:36:36.462800Z","shell.execute_reply":"2025-08-27T02:36:36.471339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split the data into train and test set\nX = sub_df.drop(columns='FLAG', axis=1)\ny = sub_df['FLAG']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:39.419102Z","iopub.execute_input":"2025-08-27T02:36:39.419395Z","iopub.status.idle":"2025-08-27T02:36:39.430304Z","shell.execute_reply.started":"2025-08-27T02:36:39.419376Z","shell.execute_reply":"2025-08-27T02:36:39.428848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Shape of X_train is {X_train.shape}\")\nprint(f\"Shape of y_train is {y_train.shape}\")\nprint(f\"Shape of X_test is {X_test.shape}\")\nprint(f\"Shape of y_test is {y_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:43.076894Z","iopub.execute_input":"2025-08-27T02:36:43.077252Z","iopub.status.idle":"2025-08-27T02:36:43.082577Z","shell.execute_reply.started":"2025-08-27T02:36:43.077231Z","shell.execute_reply":"2025-08-27T02:36:43.081546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"encoder = TargetEncoder(cols=categories)\nX_train_encoded = encoder.fit_transform(X_train, y_train)\nX_test_encoded = encoder.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:45.361260Z","iopub.execute_input":"2025-08-27T02:36:45.361600Z","iopub.status.idle":"2025-08-27T02:36:45.407166Z","shell.execute_reply.started":"2025-08-27T02:36:45.361578Z","shell.execute_reply":"2025-08-27T02:36:45.406178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_test ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:48.140693Z","iopub.execute_input":"2025-08-27T02:36:48.140978Z","iopub.status.idle":"2025-08-27T02:36:48.148838Z","shell.execute_reply.started":"2025-08-27T02:36:48.140960Z","shell.execute_reply":"2025-08-27T02:36:48.147526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.concat([X_train_encoded, y_train], axis=1)\ntest  = pd.concat([X_test_encoded, y_test], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:36:50.644280Z","iopub.execute_input":"2025-08-27T02:36:50.644622Z","iopub.status.idle":"2025-08-27T02:36:50.654271Z","shell.execute_reply.started":"2025-08-27T02:36:50.644600Z","shell.execute_reply":"2025-08-27T02:36:50.653101Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom category_encoders import TargetEncoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:47:20.859156Z","iopub.execute_input":"2025-08-27T02:47:20.860780Z","iopub.status.idle":"2025-08-27T02:47:20.868166Z","shell.execute_reply.started":"2025-08-27T02:47:20.860732Z","shell.execute_reply":"2025-08-27T02:47:20.866355Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model = IsolationForest(contamination=0.22, random_state=42)\n#model.fit(train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:47:23.491629Z","iopub.execute_input":"2025-08-27T02:47:23.491946Z","iopub.status.idle":"2025-08-27T02:47:23.506898Z","shell.execute_reply.started":"2025-08-27T02:47:23.491924Z","shell.execute_reply":"2025-08-27T02:47:23.505548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom category_encoders import TargetEncoder\n\n# Impute missing values (replace your dropping step)\ndf_imputed = df.copy()\nnumeric_cols = df_imputed.select_dtypes(include=['number']).columns\ndf_imputed[numeric_cols] = df_imputed[numeric_cols].fillna(0)\ncategorical_cols = ['ERC20_most_sent_token_type', 'ERC20_most_rec_token_type']\ndf_imputed[categorical_cols] = df_imputed[categorical_cols].fillna('Unknown')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:47:59.291933Z","iopub.execute_input":"2025-08-27T02:47:59.292377Z","iopub.status.idle":"2025-08-27T02:47:59.853889Z","shell.execute_reply.started":"2025-08-27T02:47:59.292353Z","shell.execute_reply":"2025-08-27T02:47:59.853043Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split data\nX = df_imputed.drop(columns='FLAG')\ny = df_imputed['FLAG']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Encode categorical columns\nencoder = TargetEncoder(cols=categorical_cols)\nX_train_encoded = encoder.fit_transform(X_train, y_train)\nX_test_encoded = encoder.transform(X_test)\n\n# Scale features (important for Logistic Regression)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train_encoded)\nX_test_scaled = scaler.transform(X_test_encoded)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train Logistic Regression\nlr_model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\nlr_model.fit(X_train_scaled, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict and evaluate\nlr_pred = lr_model.predict(X_test_scaled)\nprint(\"Logistic Regression Classification Report:\")\nprint(classification_report(y_test, lr_pred, target_names=['Non-Fraud (0)', 'Fraud (1)']))\n\n# Test accuracy\ntest_accuracy = (lr_pred == y_test).mean() * 100\nprint(f\"Logistic Regression Test accuracy: {test_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:53:13.233223Z","iopub.execute_input":"2025-08-27T02:53:13.233623Z","iopub.status.idle":"2025-08-27T02:53:13.251414Z","shell.execute_reply.started":"2025-08-27T02:53:13.233600Z","shell.execute_reply":"2025-08-27T02:53:13.250497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test loop for indices 500-700\nfor i in range(1000,1300):\n    example_row_scaled = X_test_scaled[i].reshape(1, -1)  # Use scaled features\n    prediction = lr_model.predict(example_row_scaled)\n    prob = lr_model.predict_proba(example_row_scaled)[0]  # Probability of each class\n    true_label = y_test.iloc[i]\n    print(f\"Index: {i}\")\n    print(f\"Prediction: {'Fraud (1)' if prediction[0] == 1 else 'Non-Fraud (0)'}\")\n    print(f\"Probability (Non-Fraud, Fraud): [{prob[0]:.4f}, {prob[1]:.4f}]\")\n    print(f\"True label (FLAG): {true_label} (1=fraud, 0=non-fraud)\")\n    print(\"\\n\")\n\n# Feature importance (coefficients)\nfeature_importance = pd.DataFrame({\n    'Feature': X_train_encoded.columns,\n    'Coefficient': lr_model.coef_[0]\n}).sort_values('Coefficient', key=abs, ascending=False)\nprint(\"Top 10 Feature Importances:\")\nprint(feature_importance.head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:53:23.138217Z","iopub.execute_input":"2025-08-27T02:53:23.138615Z","iopub.status.idle":"2025-08-27T02:53:23.279338Z","shell.execute_reply.started":"2025-08-27T02:53:23.138590Z","shell.execute_reply":"2025-08-27T02:53:23.278376Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"anomaly_train_pred = model.predict(train)\nanomaly_test_pred = model.predict(test)\n\nis_train = np.sum(anomaly_train_pred == -1)\nis_test = np.sum(anomaly_test_pred == -1)\n\nprint(f\"Number of outliers in training set is {is_train}\")\nprint(f\"Number of outliers in testing set is {is_test}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:43:35.503096Z","iopub.execute_input":"2025-08-27T02:43:35.503427Z","iopub.status.idle":"2025-08-27T02:43:35.815619Z","shell.execute_reply.started":"2025-08-27T02:43:35.503408Z","shell.execute_reply":"2025-08-27T02:43:35.814605Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"t_sne = TSNE(n_components=2, random_state=42)\nX_train_embeded = t_sne.fit_transform(X_train_encoded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:43:38.458983Z","iopub.execute_input":"2025-08-27T02:43:38.459436Z","iopub.status.idle":"2025-08-27T02:44:07.454403Z","shell.execute_reply.started":"2025-08-27T02:43:38.459406Z","shell.execute_reply":"2025-08-27T02:44:07.453729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(x = X_train_embeded[:, 0], y = X_train_embeded[:, 1], c=anomaly_train_pred)\nplt.title('t-SNE Visualization')\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:44:41.193864Z","iopub.execute_input":"2025-08-27T02:44:41.194219Z","iopub.status.idle":"2025-08-27T02:44:41.519815Z","shell.execute_reply.started":"2025-08-27T02:44:41.194195Z","shell.execute_reply":"2025-08-27T02:44:41.518894Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_embeded = t_sne.fit_transform(X_test_encoded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:44:44.841402Z","iopub.execute_input":"2025-08-27T02:44:44.841774Z","iopub.status.idle":"2025-08-27T02:44:50.976464Z","shell.execute_reply.started":"2025-08-27T02:44:44.841752Z","shell.execute_reply":"2025-08-27T02:44:50.975792Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8, 6))\nplt.scatter(x = X_test_embeded[:, 0], y = X_test_embeded[:, 1], c=anomaly_test_pred)\nplt.title('t-SNE Visualization')\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:44:54.576018Z","iopub.execute_input":"2025-08-27T02:44:54.576352Z","iopub.status.idle":"2025-08-27T02:44:54.808441Z","shell.execute_reply.started":"2025-08-27T02:44:54.576332Z","shell.execute_reply":"2025-08-27T02:44:54.807522Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After the existing predictions, add this to compute accuracy\n# First, ensure predictions are on features only (correct the fit and predict if needed)\n\n# Corrected training: Fit on features only (X_train_encoded)\nmodel = IsolationForest(contamination=0.01, random_state=42)\nmodel.fit(X_train_encoded)  # Use X_train_encoded instead of train (which includes FLAG)\n\n# Corrected predictions\nanomaly_train_pred = model.predict(X_train_encoded)\nanomaly_test_pred = model.predict(X_test_encoded)\n\n# Map predictions: -1 (anomaly) to 1 (fraud), 1 (normal) to 0 (non-fraud)\npredicted_train_label = (anomaly_train_pred == -1).astype(int)\npredicted_test_label = (anomaly_test_pred == -1).astype(int)\n\n# Compute accuracy\ntrain_accuracy = (predicted_train_label == y_train.values).mean() * 100\ntest_accuracy = (predicted_test_label == y_test.values).mean() * 100\n\nprint(f\"Training accuracy: {train_accuracy:.2f}%\")\nprint(f\"Test accuracy: {test_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:45:40.246048Z","iopub.execute_input":"2025-08-27T02:45:40.246380Z","iopub.status.idle":"2025-08-27T02:45:40.885637Z","shell.execute_reply.started":"2025-08-27T02:45:40.246358Z","shell.execute_reply":"2025-08-27T02:45:40.884491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save X_test to a CSV file\nX_test.to_csv('/kaggle/working/X_test_full.csv', index=False)\n\n# Print confirmation\nprint(\"X_test saved to /kaggle/working/X_test_full.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:45:01.171019Z","iopub.execute_input":"2025-08-27T02:45:01.171378Z","iopub.status.idle":"2025-08-27T02:45:01.227596Z","shell.execute_reply.started":"2025-08-27T02:45:01.171354Z","shell.execute_reply":"2025-08-27T02:45:01.226737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:45:02.982372Z","iopub.execute_input":"2025-08-27T02:45:02.982728Z","iopub.status.idle":"2025-08-27T02:45:03.013244Z","shell.execute_reply.started":"2025-08-27T02:45:02.982706Z","shell.execute_reply":"2025-08-27T02:45:03.012107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract the 10th row from X_test (raw features, including categorical)\ni = 1200\nexample_row = X_test.iloc[i]\ntrue_label = y_test.iloc[i]\nprint(\"True Labe:\",true_label)\n# Extract the 10th row from X_test_encoded (numerical features for model)\nexample_row_encoded = X_test_encoded.iloc[10].values.reshape(1, -1)  # Reshape to (1, 40) for predict\nprint(\"\\nEncoded features for X_test[10]:\")\nprint(example_row_encoded)\n\n# Predict anomaly\nprediction = model.predict(example_row_encoded)\nanomaly_score = model.decision_function(example_row_encoded)  # Optional: anomaly score\n\n# Get true label for comparison\n\n\n# Output results\nprint(\"\\nPrediction for X_test[\" + str(i) +\"]:\")\nprint(\"Anomaly 1\" if prediction[0] == -1 else \"Normal 0\")\nprint(f\"Anomaly score: {anomaly_score[0]:.4f} (lower is more anomalous)\")\nprint(f\"True label (FLAG): {true_label} (1=fraud, 0=non-fraud)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:45:07.534204Z","iopub.execute_input":"2025-08-27T02:45:07.534581Z","iopub.status.idle":"2025-08-27T02:45:07.617052Z","shell.execute_reply.started":"2025-08-27T02:45:07.534557Z","shell.execute_reply":"2025-08-27T02:45:07.616182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(500,700):\n    example_row = X_test.iloc[i]\n    true_label = y_test.iloc[i]\n    print(\"True Labe:\",true_label)\n    example_row_encoded = X_test_encoded.iloc[i].values.reshape(1, -1)  # Reshape to (1, 40) for predict\n    prediction = model.predict(example_row_encoded)\n    anomaly_score = model.decision_function(example_row_encoded)  # Optional: anomaly score\n    \n    print(i)\n    print(\"Anomaly 1\" if prediction[0] == -1 else \"Normal 0\")\n    print(f\"Anomaly score: {anomaly_score[0]:.4f} (lower is more anomalous)\")\n    print(f\"True label (FLAG): {true_label} (1=fraud, 0=non-fraud)\")\n    print(\"\")\n    print(\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-27T02:45:47.340143Z","iopub.execute_input":"2025-08-27T02:45:47.340488Z","iopub.status.idle":"2025-08-27T02:46:00.561397Z","shell.execute_reply.started":"2025-08-27T02:45:47.340467Z","shell.execute_reply":"2025-08-27T02:46:00.560318Z"}},"outputs":[],"execution_count":null}]}